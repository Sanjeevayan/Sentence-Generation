{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Request Offering: Request for an Equipment i.e. computer\n",
    "# Using Gensim library & word2vec model(one of the most state of the art algo to find semantic similarity of terms)\n",
    "# This word2vec model has been trained on Google news data\n",
    "# It includes word vectors for a vocabulary of 3 million words and phrases that they trained on roughly 100 billion words from a Google News dataset. The vector length is 300 \n",
    "import gensim\n",
    "\n",
    "#Load pre-trained word2vec Model\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(\"/Users/kumarsanjeev/Downloads/GoogleNews-vectors-negative300.bin\",binary = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter  an entity name:laptop\n",
      "[('laptops', 0.805374026298523), ('laptop_computer', 0.7848465442657471), ('notebook', 0.67857825756073), ('netbook', 0.6707929372787476), ('computer', 0.6640493273735046), ('laptop_computers', 0.6633790731430054), ('notebook_PC', 0.6631842851638794), ('MacBook', 0.6598750352859497), ('PowerBook', 0.6520565152168274), ('Sony_Vaio_laptop', 0.6496157646179199), ('notebooks', 0.6491786241531372), ('Macbook', 0.6486797332763672), ('Laptop', 0.648013710975647), ('IBM_ThinkPad_T##', 0.6193387508392334), ('MacBook_Pro', 0.6187069416046143), ('Dell_Latitude_D###', 0.6164904832839966), ('Macbook_Pro', 0.6115914583206177), ('computers', 0.6102420091629028), ('Dell_Inspiron_laptop', 0.6090463399887085), ('notebook_computers', 0.607465386390686)]\n"
     ]
    }
   ],
   "source": [
    "# Automatic sentence generation using Entity & Taxonomy terms  through Word2vec model\n",
    "sent = \"I want a new laptop\".split()# summary/description provided by User\n",
    "entity = input (\"Enter  an entity name:\")\n",
    "# Entity & Taxonomy terms  Extraction through Word2vec model\n",
    "entity_list = model.similar_by_word(entity ,topn=20)# word2vec Model extracts all the related terms (entity & taxonomy terms) in same semantic vector space.\n",
    "print (entity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entity & Taxonomy terms  Extraction through Word2vec model\n",
    "# import random\n",
    "# sent = \"I want a laptop\".split()\n",
    "# list1 = model.similar_by_word('laptop' ,topn=20)\n",
    "# list2 = model.similar_by_word('want', topn=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would like to have a new notebook_PC .\n",
      "I want to have a new MacBook .\n",
      "I want a new Macbook_Pro .\n",
      "I want to have a new PowerBook .\n",
      "I would like to have a new IBM_ThinkPad_T## .\n",
      "I want a new PowerBook .\n",
      "I want a new laptop_computer .\n",
      "I want a new Laptop .\n",
      "I want to have a new PowerBook .\n",
      "I want a new computer .\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "for _ in range(10):\n",
    "    subj = [\"I\"]\n",
    "    verb = [\"want\",\"need\",\"want to have\",\"would like to have\"]# Pattern words: User will have to provide keywords for the verbs to dentify the patterns. \n",
    "    det = [\"a\"]\n",
    "    adj = [\"new\"]\n",
    "    obj = []#adds all the  entities and taxonomy terms extracted by word2vec Model\n",
    "    for i in entity_list:\n",
    "        obj.append(i[0])\n",
    "\n",
    "    l=[subj,verb,det,adj,obj,\".\"] \n",
    "    m = ' '.join([random.choice(i) for i in l])\n",
    "    print (m)\n",
    "\n",
    "    # Storing the output in a text fileeee\n",
    "    s = s + m + ' \\n'\n",
    "    output_file = open(\"/Users/kumarsanjeev/Desktop/Test5.txt\")\n",
    "    path = \"/Users/kumarsanjeev/Desktop/Test5.txt\"\n",
    "    with open(path , 'w') as file:\n",
    "        file.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the output in a text file\n",
    "s = s + m + ' \\n'\n",
    "output_file = open(\"/Users/kumarsanjeev/Desktop/Test5.txt\")\n",
    "path = \"/Users/kumarsanjeev/Desktop/Test5.txt\"\n",
    "with open(path , 'w') as file:\n",
    "    file.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = input (\"Enter a pronoun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
